{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from skimage import io\n",
    "from scipy.signal import find_peaks, butter, filtfilt\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find all minis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.filters import threshold_otsu\n",
    "\n",
    "def butter_lowpass_filter(data, cutoff, fs, order=5):\n",
    "    nyq = 0.5 * fs # nyquist frequency\n",
    "    normal_cutoff = cutoff / nyq\n",
    "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "    y = filtfilt(b, a, data)\n",
    "    return y\n",
    "\n",
    "def smooth(x, axis=0, wid=5):\n",
    "    # this is way faster than convolve\n",
    "    if wid < 2:\n",
    "        return x\n",
    "    cumsum_vec = np.cumsum(np.insert(x, 0, 0, axis=axis), axis=axis)\n",
    "    ma_vec = (cumsum_vec[wid:] - cumsum_vec[:-wid]) / wid\n",
    "    y = x.copy()\n",
    "    start_ind = int(np.floor((wid-1)/2))\n",
    "    end_ind = wid-1-start_ind\n",
    "    y[start_ind:-end_ind] = ma_vec\n",
    "    return y\n",
    "\n",
    "class MiniDetector(object):\n",
    "    def __init__(self, image_path, save_dir) -> None:\n",
    "        self.img_path = image_path\n",
    "        self.save_dir = save_dir\n",
    "        self.binned_img = None\n",
    "        self.mask = None\n",
    "        self.soma_location = None\n",
    "        self.save_base_name = os.path.basename(self.img_path).split('.')[0]\n",
    "        self.filtered_traces = None\n",
    "        self.time_vector = None \n",
    "        self.mini_info_list = []\n",
    "\n",
    "    def bin_image(self, bin_size=8): \n",
    "        img = io.imread(self.img_path).astype('float32')\n",
    "        # permute image in (x,y,t) order\n",
    "        img = np.transpose(img, (2,1,0))\n",
    "\n",
    "        binned_img = np.zeros((img.shape[0]//bin_size, img.shape[1]//bin_size, img.shape[2]))\n",
    "        for i in range(binned_img.shape[0]):\n",
    "            for j in range(binned_img.shape[1]):\n",
    "                binned_img[i,j] = np.mean(img[i*bin_size:(i+1)*bin_size, j*bin_size:(j+1)*bin_size], axis=(0,1))\n",
    "        del img\n",
    "        self.binned_img = binned_img\n",
    "\n",
    "    def draw_mask(self):\n",
    "        mean_img = self.binned_img.mean(2)\n",
    "        thresh1 = threshold_otsu(mean_img)  # otsu method minimizes intra-class variance\n",
    "        neuron_mask_1 = mean_img < thresh1  # the iteration here is assuming there are 3 classes, soma, dendrite, background\n",
    "        img_2 = mean_img[neuron_mask_1]\n",
    "        thresh = threshold_otsu(img_2)\n",
    "        neuron_mask = mean_img > thresh\n",
    "        self.mask = neuron_mask\n",
    "\n",
    "    def determine_soma_location(self):\n",
    "        # determine the soma location by finding the center of the neuron mask determined by otsu method\n",
    "        mean_img = self.binned_img.mean(2)\n",
    "        thresh = threshold_otsu(mean_img) \n",
    "        neuron_mask = mean_img > thresh  # this determines the soma mask\n",
    "        x = np.where(neuron_mask)[0]\n",
    "        y = np.where(neuron_mask)[1]\n",
    "        x_center = np.mean(x)\n",
    "        y_center = np.mean(y)\n",
    "        self.soma_location = (x_center, y_center)\n",
    "\n",
    "    def mask_sanity_check(self):\n",
    "        mean_img = self.binned_img.mean(2)\n",
    "        mask = self.mask\n",
    "        # show both mean_img and mask in two plots and save as one image file\n",
    "        fig, axs = plt.subplots(1,2)\n",
    "        axs[0].imshow(mean_img, cmap='gray')\n",
    "        axs[1].imshow(mask, cmap='gray')\n",
    "        fig.savefig(os.path.join(self.save_dir, self.save_base_name+'_mask.png'))\n",
    "\n",
    "    def pre_processing(self, fs=200, cutoff=2, order=5):\n",
    "        self.bin_image()\n",
    "        self.draw_mask()\n",
    "        self.mask_sanity_check()\n",
    "        assert self.mask.sum() > 0, 'mask is empty, please check the mask'\n",
    "        neuron_traces = self.binned_img[self.mask]\n",
    "        neuron_traces = neuron_traces[:, int(fs):] # remove the first 1s of data\n",
    "        # take the 10th percentile of the mean binned_img as the baseline\n",
    "        background = np.percentile(self.binned_img.mean(2), 10)\n",
    "        neuron_traces = neuron_traces - background\n",
    "\n",
    "        neuron_traces_filt  = butter_lowpass_filter(neuron_traces, cutoff, fs, order)\n",
    "        dff = (neuron_traces - neuron_traces_filt)/neuron_traces_filt\n",
    "        self.time_vector = np.arange(neuron_traces.shape[1])/fs\n",
    "        self.filtered_traces = dff\n",
    "                \n",
    "\n",
    "    def find_mini_events(self, threshold=3.5, distance=10):\n",
    "        \"\"\"\n",
    "        threshold: the number of sigmas of the peak above the baseline\n",
    "        \"\"\"\n",
    "        dff = self.filtered_traces\n",
    "        dff_std = dff.std(1)\n",
    "        mini_info_list = []\n",
    "        for trace_id in range(dff.shape[0]):\n",
    "            peaks, _ = find_peaks(-dff[trace_id], height=dff_std[trace_id]*threshold, distance=10)\n",
    "            # convert trace_id to x,y coordinates\n",
    "            x = np.where(self.mask)[0][trace_id]\n",
    "            y = np.where(self.mask)[1][trace_id]\n",
    "            if len(peaks) > 0:\n",
    "                mini_info_list.append({'id':trace_id, 'x':x, 'y':y, 'peaks':peaks, 'dff':dff[trace_id]})\n",
    "        self.mini_info_list = mini_info_list\n",
    "\n",
    "    def save_data(self):\n",
    "        # save the mini_info_list as a pickle file\n",
    "        with open(os.path.join(self.save_dir, self.save_base_name+'_mini_info_list.pkl'), 'wb') as f:\n",
    "            pickle.dump(self.mini_info_list, f)\n",
    "            pickle.dump(self.binned_img, f)\n",
    "            pickle.dump(self.mask, f)\n",
    "                \n",
    "    def plot_traces(self, pixel_id=0, save_file=False):\n",
    "        # plot the raw trace and the filtered trace\n",
    "        peaks = self.mini_info_list[pixel_id]['peaks']\n",
    "        x = self.mini_info_list[pixel_id]['x']\n",
    "        y = self.mini_info_list[pixel_id]['y']\n",
    "        dff = self.mini_info_list[pixel_id]['dff']\n",
    "        # plot the trace with peaks, and the pixel on the binned image\n",
    "        fig, axs = plt.subplots(2,1)\n",
    "        axs[0].plot(self.time_vector, dff)\n",
    "        axs[0].plot(self.time_vector[peaks], dff[peaks], '^')\n",
    "        axs[0].set_xlabel('Time (s)')\n",
    "        axs[0].set_ylabel('dF/F')\n",
    "        axs[0].set_title('Filtered trace')\n",
    "        axs[1].imshow(self.binned_img.mean(2), cmap='gray')\n",
    "        axs[1].plot(y, x, 'x', color='red')\n",
    "        axs[1].set_title('Pixel location')\n",
    "\n",
    "        if save_file:\n",
    "            fig.savefig(os.path.join(self.save_dir, self.save_base_name+'_trace.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img_path = '/Volumes/CLab/dendritic_scaling/test/hSyn-5f-corti-DIV21-Flash4v2-well3-TTXPTX-FOV13p9-482ex-200fps103-93-12092.tif'\n",
    "save_dir = '/Volumes/CLab/dendritic_scaling/test/results'\n",
    "test_img_path = '/Users/ykhao/Downloads/mini_analysis/figure5A_neuron_example_nonTTX/rat-hippo-5f-cs1cell1p5-200Hz-currentclamp_rolling fixed_5kfr_cropped.tif'\n",
    "save_dir = '/Users/ykhao/Downloads/mini_analysis/figure5A_neuron_example_nonTTX/results0p5Hz'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "mini_detector = MiniDetector(test_img_path, save_dir)\n",
    "mini_detector.pre_processing()\n",
    "mini_detector.find_mini_events()\n",
    "mini_detector.save_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detected_traces = [item['dff'] for item in mini_detector.mini_info_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_detector.plot_traces(pixel_id=51)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(mini_detector.time_vector, np.mean(detected_traces, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = '/Volumes/CLab/dendritic_scaling/test/'\n",
    "img_paths = glob.glob(os.path.join(img_dir, '*.tif'))\n",
    "save_dir = os.path.join(img_dir, 'results')\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "for img_path in img_paths:\n",
    "    print('Processing {}'.format(img_path))\n",
    "    mini_detector = MiniDetector(img_path, save_dir)\n",
    "    mini_detector.pre_processing()\n",
    "    mini_detector.find_mini_events()\n",
    "    mini_detector.save_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the template signal for mini events\n",
    "t = np.arange(-20, 20, 1)\n",
    "# for t>0, the signal is exp decay from 1.0, time constant is 3\n",
    "# for t<0, the signal is zero, and when t=0, the signal is 1\n",
    "template_signal = np.zeros(len(t))\n",
    "template_signal[t>=0] = np.exp(-t[t>=0]/4)\n",
    "template_signal[t==0] = 1\n",
    "template_signal[t==-1] = 0.5\n",
    "plt.plot(t, template_signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_signal_centroid(t, signal):\n",
    "    # get the centroid of the signal\n",
    "    # the signal is a 1D array\n",
    "    # the centroid is the weighted average of the signal\n",
    "    assert len(t) == len(signal), 't and signal must have the same length'\n",
    "    centroid = np.sum(signal*t)/np.sum(signal)\n",
    "    return centroid\n",
    "\n",
    "class Propagation(object):\n",
    "    # this class is used to store the propagation information\n",
    "    # propagation class will have the information of a list of detected mini events\n",
    "    # And also a method to determine filter out the falsely included mini events according to the peak positions\n",
    "    def __init__(self, mini_list) -> None:\n",
    "        self.mini_list = mini_list\n",
    "\n",
    "    def get_mean_peak(self):\n",
    "        # get the weighted average of the peak positions\n",
    "        peak_list = []\n",
    "        dff_list = []\n",
    "        for item in self.mini_list:\n",
    "            peak_list.append(item[2])\n",
    "            dff_list.append(np.abs(item[3]))\n",
    "        return np.average(peak_list, weights=dff_list)\n",
    "    \n",
    "    def clear_false_events(self, threshold=3):\n",
    "        # remove the false events by comparing the peak positions\n",
    "        # if the peak position is too far from the main peak, then remove it\n",
    "        centroid_center = self.get_mean_peak()\n",
    "        filtered_mini_list = []\n",
    "        for item in self.mini_list:\n",
    "            peak = item[2]\n",
    "            if abs(peak - centroid_center) <= threshold:\n",
    "                filtered_mini_list.append(item)\n",
    "        self.mini_list = filtered_mini_list\n",
    "\n",
    "    def get_propagation_length(self):\n",
    "        # get the number of locations involved in the propagation\n",
    "        return len(self.mini_list)\n",
    "\n",
    "    def get_mean_waveform(self):\n",
    "        # get the mean waveform of the propagation\n",
    "        # first get the mean peak location\n",
    "        mean_peak = int(np.round(self.get_mean_peak()))\n",
    "        # then get the mean waveform\n",
    "        all_trace_near_peak = []\n",
    "        for item in self.mini_list:\n",
    "            dff = item[4]\n",
    "            all_trace_near_peak.append(dff[mean_peak-20:mean_peak+20])\n",
    "        mean_waveform = np.mean(all_trace_near_peak, axis=0)\n",
    "        return mean_waveform\n",
    "\n",
    "    def cross_correlation(self, template_signal):\n",
    "        # get the cross correlation between the mean waveform and the template signal\n",
    "        mean_waveform = -self.get_mean_waveform()\n",
    "        #corr = np.correlate(mean_waveform, template_signal)\n",
    "        corr = np.sum(mean_waveform*template_signal[:len(mean_waveform)])\n",
    "        return corr/np.sqrt(np.sum(mean_waveform**2)*np.sum(template_signal**2))\n",
    "\n",
    "\n",
    "class PropagationDetector(object):\n",
    "    def __init__(self, mini_info_path) -> None:\n",
    "        self.mini_info_path = mini_info_path\n",
    "        self.save_dir = mini_info_path.split('.')[0]\n",
    "        self.propagation_list = []  # a list of propagation objects\n",
    "        self.mini_info_list = None\n",
    "        self.binned_img = None\n",
    "        self.mask = None\n",
    "        self.all_peak_locations = None\n",
    "\n",
    "    def load_data(self):\n",
    "        with open(self.mini_info_path, 'rb') as f:\n",
    "            self.mini_info_list = pickle.load(f)\n",
    "            self.binned_img = pickle.load(f)\n",
    "            self.mask = pickle.load(f)\n",
    "        peak_list_of_all_traces = []\n",
    "\n",
    "        for item in self.mini_info_list:\n",
    "            peaks = item['peaks']\n",
    "            peak_list_of_all_traces.append(peaks.tolist())\n",
    "        \n",
    "        all_peaks = []\n",
    "        for item in peak_list_of_all_traces:\n",
    "            all_peaks += item\n",
    "        all_peak_unique = np.sort(np.unique(all_peaks))\n",
    "        all_peak_unique = all_peak_unique[all_peak_unique > 40] # remove the first 40 frames to avoid the artifact\n",
    "        self.all_peak_locations = all_peak_unique[all_peak_unique < len(self.mini_info_list[0]['dff'])-40]\n",
    "\n",
    "    \n",
    "    def find_consecutive_peaks(self, distance=5):\n",
    "        all_peak_unique = self.all_peak_locations\n",
    "        if all_peak_unique is None:\n",
    "            self.load_data()\n",
    "            all_peak_unique = self.all_peak_locations\n",
    "        consecutive_peaks_groups = []\n",
    "        current_group = []\n",
    "        for i in range(len(all_peak_unique)-1):\n",
    "            if all_peak_unique[i+1] - all_peak_unique[i] < distance:\n",
    "                current_group.append(all_peak_unique[i])\n",
    "            else:\n",
    "                current_group.append(all_peak_unique[i])\n",
    "                consecutive_peaks_groups.append(current_group)\n",
    "                current_group = []\n",
    "        self.consecutive_peaks_groups = consecutive_peaks_groups\n",
    "    \n",
    "    def find_propagation(self, minimal_mini_number=3, template_matching_threshold=0.6):\n",
    "        for group in self.consecutive_peaks_groups:\n",
    "            propagation_event = []\n",
    "            for item in self.mini_info_list:\n",
    "                peaks = item['peaks']\n",
    "                dff = item['dff']\n",
    "                x = item['x']\n",
    "                y = item['y']\n",
    "                for peak in peaks:\n",
    "                    if peak in group:\n",
    "                        propagation_event.append((x, y, peak, dff[peak], dff))\n",
    "            propagation = Propagation(propagation_event)\n",
    "            propagation.clear_false_events()\n",
    "            template_matching_score = propagation.cross_correlation(template_signal)\n",
    "            if propagation.get_propagation_length() > minimal_mini_number and template_matching_score > template_matching_threshold:\n",
    "                self.propagation_list.append(propagation)\n",
    "    \n",
    "    def show_propagation(self):\n",
    "        for propagation in self.propagation_list:\n",
    "            n_peaks = propagation.get_propagation_length()\n",
    "            cmaps=sns.color_palette(\"Set2\", n_colors=n_peaks)\n",
    "            if n_peaks > 15:\n",
    "                print('Too many peaks, show only the first 15 peaks')\n",
    "                n_peaks = 15\n",
    "            fig, axs = plt.subplots(1, n_peaks+2, figsize=(3*n_peaks+6, 5))\n",
    "            # plot the mean image and the pixel locations\n",
    "            axs[0].imshow(self.binned_img.mean(2), cmap='gray')\n",
    "            for i,item in enumerate(propagation.mini_list):\n",
    "                x = item[0]\n",
    "                y = item[1]\n",
    "                axs[0].plot(y, x, 'x', color=cmaps[i])\n",
    "            # plot the dff trace around each peak\n",
    "            mean_peak = int(np.round(propagation.get_mean_peak()))\n",
    "            all_trace_near_peak = []\n",
    "            for i in range(n_peaks):\n",
    "                propogation_info = propagation.mini_list\n",
    "                x = propogation_info[i][0]\n",
    "                y = propogation_info[i][1]\n",
    "                peak = propogation_info[i][2]\n",
    "                dff = propogation_info[i][4]\n",
    "                show_window = [peak-20,peak+20]\n",
    "                if show_window[0] < 0:\n",
    "                    show_window = [0, 40]\n",
    "                if show_window[1] > len(dff):\n",
    "                    show_window = [len(dff)-40, len(dff)]\n",
    "                axs[i+1].plot(np.arange(show_window[0],show_window[1],1), dff[show_window[0]:show_window[1]], color=cmaps[i])\n",
    "                axs[i+1].set_ylim([-0.15, 0.05])\n",
    "                axs[i+1].axvline(x=propagation.get_mean_peak(), color='red', linestyle='--')\n",
    "                axs[i+1].set_title('x={}, y={}'.format(x, y))\n",
    "                all_trace_near_peak.append(dff[mean_peak-20:mean_peak+20])\n",
    "            # plot the mean trace\n",
    "            mean_trace = np.mean(all_trace_near_peak, axis=0)\n",
    "            axs[-1].plot(np.arange(-20,20,1), mean_trace, color='black')\n",
    "            axs[-1].set_ylim([-0.15, 0.05])\n",
    "            axs[-1].set_title('cor={}'.format(propagation.cross_correlation(template_signal)))\n",
    "            if not os.path.exists(self.save_dir):\n",
    "                os.makedirs(self.save_dir)\n",
    "            fig.savefig(os.path.join(self.save_dir, 'propagation_{}.png'.format(self.propagation_list.index(propagation))))\n",
    "            plt.close(fig)\n",
    "\n",
    "    def save_propagation(self):\n",
    "        # if the propagation_list is not empty, then save it as a pickle file\n",
    "        if len(self.propagation_list) > 0:\n",
    "            with open(os.path.join(self.save_dir, 'propagation_list.pkl'), 'wb') as f:\n",
    "                pickle.dump(self.propagation_list, f)\n",
    "    \n",
    "    def save_propagation_as_mat(self):\n",
    "        # save the propagation in the propagation list as seperate mat files\n",
    "        for propagation in self.propagation_list:\n",
    "            propagation_info = propagation.mini_list\n",
    "            x = [item[0] for item in propagation_info]\n",
    "            y = [item[1] for item in propagation_info]\n",
    "            peak = [item[2] for item in propagation_info]\n",
    "            dff_around_peak = []\n",
    "            for item in propagation_info:\n",
    "                dff_around_peak.append(item[4][item[2]-20:item[2]+20])\n",
    "            sio.savemat(os.path.join(self.save_dir, 'propagation_{}.mat'.format(self.propagation_list.index(propagation))),\n",
    "                        {'x':x, 'y':y, 'peak':peak, 'dff_around_peak':dff_around_peak})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_dir = '/Volumes/CLab/dendritic_scaling/test/results'\n",
    "pkl_paths = glob.glob(os.path.join(working_dir, '*.pkl'))\n",
    "pkl_path = pkl_paths[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "propagation_detector = PropagationDetector(pkl_path)\n",
    "propagation_detector.load_data()\n",
    "propagation_detector.find_consecutive_peaks()\n",
    "propagation_detector.find_propagation(minimal_mini_number=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "propagation_detector.show_propagation(propagation_id=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#working_dir = '/Volumes/CLab/dendritic_scaling/20231212_B33-neurons-DIV21_dendritic-scaling/Well2/B33-DIV21-corti-glassbottom-well2-TIFF/results'\n",
    "working_dir = '/Volumes/CLab/dendritic_scaling/20231212_B33-neurons-DIV21_dendritic-scaling/Well3/B33-DIV21-corti-glassbottom-well3-TIFF/TTX/results'\n",
    "#working_dir = '/Volumes/CLab/dendritic_scaling/20231212_B33-neurons-DIV21_dendritic-scaling/Well4/B33-DIV21-corti-glassbottom-well4-TIFF/results'\n",
    "#working_dir = '/Volumes/CLab/dendritic_scaling/test/results'\n",
    "working_dir = '/Users/ykhao/Downloads/mini_analysis/figure5A_neuron_example_nonTTX/results0p5Hz/'\n",
    "pkl_paths = glob.glob(os.path.join(working_dir, '*.pkl'))\n",
    "for pkl_path in pkl_paths:\n",
    "    propagation_detector = PropagationDetector(pkl_path)\n",
    "    propagation_detector.load_data()\n",
    "    propagation_detector.find_consecutive_peaks(distance=5)\n",
    "    propagation_detector.find_propagation(minimal_mini_number=5, template_matching_threshold=0.75)\n",
    "    propagation_detector.show_propagation()\n",
    "    propagation_detector.save_propagation()\n",
    "    propagation_detector.save_propagation_as_mat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_dir_list = [\n",
    "#     '/Volumes/CLab/dendritic_scaling/20231215_B33_neurons_DIV24_dendritic_scaling_2/B2-470/B33-DIV24-B2-470-TIFF/TTX',\n",
    "#     '/Volumes/CLab/dendritic_scaling/20231215_B33_neurons_DIV24_dendritic_scaling_2/B3-470/B33-DIV24-B3-470-TIFF/TTX',\n",
    "#     '/Volumes/CLab/dendritic_scaling/20231215_B33_neurons_DIV24_dendritic_scaling_2/C2-482/B33-DIV24-C2-482-TIFF/TTX',\n",
    "#     '/Volumes/CLab/dendritic_scaling/20231215_B33_neurons_DIV24_dendritic_scaling_2/C3-482/B33-DIV24-C3-482-TIFF/TTX',\n",
    "#     '/Volumes/CLab/dendritic_scaling/20231212_B33-neurons-DIV21_dendritic-scaling/Well2/B33-DIV21-corti-glassbottom-well2-TIFF/TTX',\n",
    "#     '/Volumes/CLab/dendritic_scaling/20231212_B33-neurons-DIV21_dendritic-scaling/Well3/B33-DIV21-corti-glassbottom-well3-TIFF/TTX',\n",
    "#     '/Volumes/CLab/dendritic_scaling/20231212_B33-neurons-DIV21_dendritic-scaling/Well4/B33-DIV21-corti-glassbottom-well4-TIFF/TTX']\n",
    "# image_dir_list = [\n",
    "#     '/Volumes/MyPassport/dendritic_scaling/20240209/C1_wellB2/TTX_PTX/',\n",
    "#     '/Volumes/MyPassport/dendritic_scaling/20240209/C1_wellC2/TTX_PTX/',\n",
    "#     '/Volumes/MyPassport/dendritic_scaling/20240209/C1_wellC3/TTX_PTX/']\n",
    "# image_dir_list = [\n",
    "#     '/Volumes/MyPassport/dendritic_scaling/20240210/plateC2_WellB2/TTX_PTX/',\n",
    "#     '/Volumes/MyPassport/dendritic_scaling/20240210/plateC2_WellB3/TTX_PTX/',\n",
    "#     '/Volumes/MyPassport/dendritic_scaling/20240210/plateC2_WellC2/TTX_PTX/',\n",
    "#     '/Volumes/MyPassport/dendritic_scaling/20240210/plateC2_WellC3/TTX_PTX/']\n",
    "# image_dir_list = [\n",
    "#     '/Volumes/MyPassport/dendritic_scaling/20240215/plateC3_WellB2/TTX_PTX/',\n",
    "#     '/Volumes/MyPassport/dendritic_scaling/20240215/plateC3_WellB3/TTX_PTX/',\n",
    "#     '/Volumes/MyPassport/dendritic_scaling/20240215/plateC3_WellB4/TTX_PTX/',\n",
    "#     '/Volumes/MyPassport/dendritic_scaling/20240215/plateC3_WellC2/TTX_PTX/',\n",
    "#     '/Volumes/MyPassport/dendritic_scaling/20240215/plateC3_WellC3/TTX_PTX/']\n",
    "image_dir_list = [\n",
    "    '/Volumes/MyPassport/dendritic_scaling/20240216/plateC2_WellB2/',\n",
    "    '/Volumes/MyPassport/dendritic_scaling/20240216/plateC2_WellB3/',\n",
    "    '/Volumes/MyPassport/dendritic_scaling/20240216/plateC2_WellC2/',\n",
    "    '/Volumes/MyPassport/dendritic_scaling/20240216/plateC2_WellC3/']\n",
    "# image_dir_list = [\n",
    "#      '/Volumes/MyPassport/dendritic_scaling/20240210/plateC2_WellB2/W-view-images/TTX_PTX/']\n",
    "\n",
    "for image_dir in image_dir_list:\n",
    "    pkl_paths = glob.glob(os.path.join(image_dir, 'results', '*.pkl'))\n",
    "    for pkl_path in pkl_paths:\n",
    "        propagation_detector = PropagationDetector(pkl_path)\n",
    "        propagation_detector.load_data()\n",
    "        propagation_detector.find_consecutive_peaks()\n",
    "        propagation_detector.find_propagation(minimal_mini_number=5, template_matching_threshold=0.75)\n",
    "        propagation_detector.show_propagation()\n",
    "        propagation_detector.save_propagation()\n",
    "        propagation_detector.save_propagation_as_mat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir_list = [\n",
    "    '/Volumes/MyPassport/dendritic_scaling/20240209/C1_wellB2/TTX_PTX/',\n",
    "    '/Volumes/MyPassport/dendritic_scaling/20240209/C1_wellC2/TTX_PTX/',\n",
    "    '/Volumes/MyPassport/dendritic_scaling/20240209/C1_wellC3/TTX_PTX/',\n",
    "    '/Volumes/MyPassport/dendritic_scaling/20240210/plateC2_WellB2/TTX_PTX/',\n",
    "    '/Volumes/MyPassport/dendritic_scaling/20240210/plateC2_WellB3/TTX_PTX/',\n",
    "    '/Volumes/MyPassport/dendritic_scaling/20240210/plateC2_WellC2/TTX_PTX/',\n",
    "    '/Volumes/MyPassport/dendritic_scaling/20240210/plateC2_WellC3/TTX_PTX/',\n",
    "    '/Volumes/MyPassport/dendritic_scaling/20240210/plateC2_WellB2/W-view-images/TTX_PTX/']\n",
    "\n",
    "for image_dir in image_dir_list:\n",
    "    pkl_paths = glob.glob(os.path.join(image_dir, 'results0p5Hz', '*.pkl'))\n",
    "    for pkl_path in pkl_paths:\n",
    "        propagation_detector = PropagationDetector(pkl_path)\n",
    "        propagation_detector.load_data()\n",
    "        propagation_detector.find_consecutive_peaks()\n",
    "        propagation_detector.find_propagation(minimal_mini_number=5, template_matching_threshold=0.75)\n",
    "        propagation_detector.show_propagation()\n",
    "        propagation_detector.save_propagation()\n",
    "        propagation_detector.save_propagation_as_mat()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flybrain2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
