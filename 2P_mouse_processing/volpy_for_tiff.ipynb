{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import h5py\n",
    "import pickle\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "from skimage import io\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal, ndimage\n",
    "\n",
    "from roifile import ImagejRoi\n",
    "import caiman as cm\n",
    "import caiman.paths\n",
    "from caiman.source_extraction.volpy import utils\n",
    "from caiman.source_extraction.volpy.volparams import volparams\n",
    "from caiman.source_extraction.volpy.volpy import VOLPY\n",
    "from caiman.source_extraction.volpy.spikepursuit import signal_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#working_dir = '/Volumes/CLab/hour_long_recording/record3/moco_aff_crop/'\n",
    "working_dir = '/Volumes/CLab/hour_long_recording_jedi/recording1/moco_aff_crop/'\n",
    "img_list = glob.glob(os.path.join(working_dir, '*.tif'))\n",
    "\n",
    "save_dir = os.path.join(working_dir, 'volpy_results')\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = None                                # if None, use ROIs for initialization; to reuse weights check reuse weights block \n",
    "\n",
    "fr = 500 \n",
    "template_size = 0.01                          # half size of the window length for spike templates, default is 20 ms \n",
    "context_size = 1                          # number of pixels surrounding the ROI to censor from the background PCA\n",
    "visualize_ROI = False                         # whether to visualize the region of interest inside the context region\n",
    "flip_signal = True                            # Important!! Flip signal or not, True for Voltron indicator, False for others\n",
    "hp_freq_pb = 1 / 3                            # parameter for high-pass filter to remove photobleaching\n",
    "hp_freq = 10\n",
    "clip = 100                                    # maximum number of spikes to form spike template\n",
    "threshold_method = 'adaptive_threshold'       # adaptive_threshold or simple \n",
    "min_spikes= 4                                # minimal spikes to be found  # was 50 for Jiannis' data\n",
    "pnorm = 0.5                                   # a variable deciding the amount of spikes chosen for adaptive threshold method\n",
    "desired_fp = 10**(-4)  # note: was hard-coded for current use case\n",
    "threshold = 3                                 # threshold for finding spikes only used in simple threshold method, Increase the threshold to find less spikes\n",
    "do_plot = False                               # plot detail of spikes, template for the last iteration\n",
    "ridge_bg= 0.01                                # ridge regression regularizer strength for background removement, larger value specifies stronger regularization \n",
    "sub_freq = 20                                 # frequency for subthreshold extraction\n",
    "weight_update = 'ridge'                       # ridge or NMF for weight update\n",
    "n_iter = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth(x, axis=0, wid=5):\n",
    "    # this is way faster than convolve\n",
    "    if wid < 2:\n",
    "        return x\n",
    "    cumsum_vec = np.cumsum(np.insert(x, 0, 0, axis=axis), axis=axis)\n",
    "    ma_vec = (cumsum_vec[wid:] - cumsum_vec[:-wid]) / wid\n",
    "    y = x.copy()\n",
    "    start_ind = int(np.floor((wid-1)/2))\n",
    "    end_ind = wid-1-start_ind\n",
    "    y[start_ind:-end_ind] = ma_vec\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_moving_frames(img, mean_img, thr=0.7):\n",
    "    img_smoothed = smooth(img, axis=0, wid=10)\n",
    "    corr_series = np.zeros((img.shape[0], ))\n",
    "    # compute the cross correlation between the mean image and every frame\n",
    "    for i in np.arange(img_smoothed.shape[0]):\n",
    "        tmp = img_smoothed[i, :, :]\n",
    "        corr_series[i] = np.corrcoef(tmp.ravel(), mean_img.ravel())[0, 1]\n",
    "    \n",
    "    moving_frame_mask = corr_series < thr\n",
    "    # blur the mask to remove the boundary effect\n",
    "    moving_frame_mask = ndimage.gaussian_filter1d(moving_frame_mask.astype(np.float), sigma=200)\n",
    "    removed_frames = np.where(moving_frame_mask > 0.0)[0]\n",
    "    raw_img_index = np.arange(img.shape[0])\n",
    "    # remove the frames with low correlation\n",
    "    img = np.delete(img, removed_frames, axis=0)\n",
    "    img_index = np.delete(raw_img_index, removed_frames, axis=0)\n",
    "    current_to_raw_mapping = {i: j for i, j in zip(np.arange(img.shape[0]), img_index)}\n",
    "\n",
    "    return img, current_to_raw_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_list.sort()\n",
    "for img_path in img_list:\n",
    "    ## read image and ROI\n",
    "    img = io.imread(img_path)\n",
    "    mean_img = img.mean(axis=0)\n",
    "    img, current_to_raw_mapping = remove_moving_frames(img, mean_img)\n",
    "    ROI_path = img_path[:-11] + '_moco_mask.h5'\n",
    "    img_id = os.path.basename(img_path).replace('.tif', '')\n",
    "    print(img_id)\n",
    "    with h5py.File(ROI_path, 'r') as fl:\n",
    "        ROI = fl['cell_mask'][()]\n",
    "    #img = remove_moving_frames(img, ROI)\n",
    "    T, d1, d2 = img.shape\n",
    "    img_reshape = img.reshape(T, d1*d2, order='F')\n",
    "    ## generating memory mapping\n",
    "    mmap_path = caiman.paths.memmap_frames_filename(img_id[:15], [d1, d2], T, 'C')\n",
    "    mmap_path = os.path.join(working_dir, mmap_path)\n",
    "    fp = np.memmap(mmap_path, dtype='float32', mode='w+', shape=(d1*d2, T), order='C')\n",
    "    fp[:] = img_reshape[:].T\n",
    "    fp.flush()\n",
    "    del fp\n",
    "    ## assembly parameters for volpy\n",
    "    ROIs = np.expand_dims(ROI.T, axis=0)\n",
    "    index = list(range(len(ROIs)))     # index of ROIs to be used for spike extraction\n",
    "    opts_dict={'fnames': mmap_path,\n",
    "            'ROIs': ROIs,\n",
    "            'fr': fr,\n",
    "            'index': index,\n",
    "            'weights': weights,\n",
    "            'template_size': template_size, \n",
    "            'context_size': context_size,\n",
    "            'visualize_ROI': visualize_ROI, \n",
    "            'flip_signal': flip_signal,\n",
    "            'hp_freq': hp_freq,\n",
    "            'hp_freq_pb': hp_freq_pb,\n",
    "            'clip': clip,\n",
    "            'threshold_method': threshold_method,\n",
    "            'min_spikes':min_spikes,\n",
    "            'pnorm': pnorm,\n",
    "            #'desired_fp': desired_fp, \n",
    "            'threshold': threshold,\n",
    "            'do_plot':do_plot,\n",
    "            'ridge_bg':ridge_bg,\n",
    "            'sub_freq': sub_freq,\n",
    "            'weight_update': weight_update,\n",
    "            'n_iter': n_iter}\n",
    "\n",
    "    opts = volparams(params_dict=opts_dict)\n",
    "    ## run volpy\n",
    "    if 'dview' in locals():\n",
    "        cm.stop_server(dview=dview)\n",
    "    c, dview, n_processes = cm.cluster.setup_cluster(\n",
    "        backend='local', n_processes=None, single_thread=False)\n",
    "    # try:\n",
    "    vpy = VOLPY(n_processes=n_processes, dview=dview, params=opts)\n",
    "    vpy.fit(n_processes=n_processes, dview=dview)\n",
    "    ## visualize and save results\n",
    "    print(np.where(vpy.estimates['locality'])[0])    # neurons that pass locality test\n",
    "    idx = np.where(vpy.estimates['locality'] > 0)[0]\n",
    "    utils.view_components(vpy.estimates, mean_img, [0], save_path=os.path.join(save_dir, img_id + '_summary.png'))\n",
    "    spike_locs = vpy.estimates['spikes'].copy().ravel()\n",
    "    for i, loc in enumerate(spike_locs):\n",
    "        spike_locs[i] = current_to_raw_mapping[loc]\n",
    "    vpy.estimates['spikes'] = spike_locs\n",
    "    with open(os.path.join(save_dir, img_id + '_volpy.pkl'), 'wb') as f:\n",
    "        pickle.dump(vpy.estimates, f)\n",
    "    # except:\n",
    "    #     shutil.move(src=img_path, dst=os.path.join(working_dir, 'failed'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 min analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_dir = '/Volumes/CLab/hour_long_recording/ASAP5_4min/moco_aff_crop'\n",
    "working_dir = '/Volumes/CLab/hour_long_recording_jedi/jedi_4min/moco_aff_crop'\n",
    "\n",
    "img_list = glob.glob(os.path.join(working_dir, '*.tif'))\n",
    "\n",
    "save_dir = os.path.join(working_dir, 'volpy_results')\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = None                                # if None, use ROIs for initialization; to reuse weights check reuse weights block \n",
    "\n",
    "fr = 500 \n",
    "template_size = 0.01                          # half size of the window length for spike templates, default is 20 ms \n",
    "context_size = 1                          # number of pixels surrounding the ROI to censor from the background PCA\n",
    "visualize_ROI = False                         # whether to visualize the region of interest inside the context region\n",
    "flip_signal = True                            # Important!! Flip signal or not, True for Voltron indicator, False for others\n",
    "hp_freq_pb = 1 / 3                            # parameter for high-pass filter to remove photobleaching\n",
    "hp_freq = 10\n",
    "clip = 100                                    # maximum number of spikes to form spike template\n",
    "threshold_method = 'adaptive_threshold'       # adaptive_threshold or simple \n",
    "min_spikes= 5                                # minimal spikes to be found  # was 50 for Jiannis' data\n",
    "pnorm = 0.5                                   # a variable deciding the amount of spikes chosen for adaptive threshold method\n",
    "desired_fp = 10**(-4)  # note: was hard-coded for current use case\n",
    "threshold = 3                                 # threshold for finding spikes only used in simple threshold method, Increase the threshold to find less spikes\n",
    "do_plot = False                               # plot detail of spikes, template for the last iteration\n",
    "ridge_bg= 0.01                                # ridge regression regularizer strength for background removement, larger value specifies stronger regularization \n",
    "sub_freq = 20                                 # frequency for subthreshold extraction\n",
    "weight_update = 'ridge'                       # ridge or NMF for weight update\n",
    "n_iter = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_list.sort()\n",
    "for img_path in img_list:\n",
    "    ## read image and ROI\n",
    "    img = io.imread(img_path)\n",
    "    mean_img = img.mean(axis=0)\n",
    "    img, current_to_raw_mapping = remove_moving_frames(img, mean_img)\n",
    "    ROI_path = img_path[:-4] + '_mask.h5'\n",
    "    img_id = os.path.basename(img_path).replace('.tif', '')\n",
    "    print(img_id)\n",
    "    with h5py.File(ROI_path, 'r') as fl:\n",
    "        ROI = fl['cell_mask'][()]\n",
    "    #img = remove_moving_frames(img, ROI)\n",
    "    T, d1, d2 = img.shape\n",
    "    img_reshape = img.reshape(T, d1*d2, order='F')\n",
    "    ## generating memory mapping\n",
    "    mmap_path = caiman.paths.memmap_frames_filename(img_id[:15], [d1, d2], T, 'C')\n",
    "    mmap_path = os.path.join(working_dir, mmap_path)\n",
    "    fp = np.memmap(mmap_path, dtype='float32', mode='w+', shape=(d1*d2, T), order='C')\n",
    "    fp[:] = img_reshape[:].T\n",
    "    fp.flush()\n",
    "    del fp\n",
    "    ## assembly parameters for volpy\n",
    "    ROIs = np.expand_dims(ROI.T, axis=0)\n",
    "    index = list(range(len(ROIs)))     # index of ROIs to be used for spike extraction\n",
    "    opts_dict={'fnames': mmap_path,\n",
    "            'ROIs': ROIs,\n",
    "            'fr': fr,\n",
    "            'index': index,\n",
    "            'weights': weights,\n",
    "            'template_size': template_size, \n",
    "            'context_size': context_size,\n",
    "            'visualize_ROI': visualize_ROI, \n",
    "            'flip_signal': flip_signal,\n",
    "            'hp_freq': hp_freq,\n",
    "            'hp_freq_pb': hp_freq_pb,\n",
    "            'clip': clip,\n",
    "            'threshold_method': threshold_method,\n",
    "            'min_spikes':min_spikes,\n",
    "            'pnorm': pnorm,\n",
    "            #'desired_fp': desired_fp, \n",
    "            'threshold': threshold,\n",
    "            'do_plot':do_plot,\n",
    "            'ridge_bg':ridge_bg,\n",
    "            'sub_freq': sub_freq,\n",
    "            'weight_update': weight_update,\n",
    "            'n_iter': n_iter}\n",
    "\n",
    "    opts = volparams(params_dict=opts_dict)\n",
    "    ## run volpy\n",
    "    if 'dview' in locals():\n",
    "        cm.stop_server(dview=dview)\n",
    "    c, dview, n_processes = cm.cluster.setup_cluster(\n",
    "        backend='local', n_processes=None, single_thread=False)\n",
    "    # try:\n",
    "    vpy = VOLPY(n_processes=n_processes, dview=dview, params=opts)\n",
    "    vpy.fit(n_processes=n_processes, dview=dview)\n",
    "    ## visualize and save results\n",
    "    print(np.where(vpy.estimates['locality'])[0])    # neurons that pass locality test\n",
    "    idx = np.where(vpy.estimates['locality'] > 0)[0]\n",
    "    utils.view_components(vpy.estimates, mean_img, [0], save_path=os.path.join(save_dir, img_id + '_summary.png'))\n",
    "    spike_locs = vpy.estimates['spikes'].copy().ravel()\n",
    "    for i, loc in enumerate(spike_locs):\n",
    "        spike_locs[i] = current_to_raw_mapping[loc]\n",
    "    vpy.estimates['spikes'] = spike_locs\n",
    "    with open(os.path.join(save_dir, img_id + '_volpy.pkl'), 'wb') as f:\n",
    "        pickle.dump(vpy.estimates, f)\n",
    "    # except:\n",
    "    #     shutil.move(src=img_path, dst=os.path.join(working_dir, 'failed'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img_path in img_list:\n",
    "    ## read image and ROI\n",
    "    img = io.imread(img_path)\n",
    "    mean_img = img.mean(axis=0)\n",
    "    img, current_to_raw_mapping = remove_moving_frames(img, mean_img)\n",
    "    img_id = os.path.basename(img_path).replace('.tif', '')\n",
    "    with open(os.path.join(save_dir, img_id + '_volpy.pkl'), 'rb') as f:\n",
    "        estimates = pickle.load(f)\n",
    "        spike_locs = estimates['spikes'].copy().ravel()\n",
    "        for i, loc in enumerate(spike_locs):\n",
    "            spike_locs[i] = current_to_raw_mapping[loc]\n",
    "        estimates['spikes'] = spike_locs\n",
    "        with open(os.path.join(save_dir, img_id + '_volpy.pkl'), 'wb') as f:\n",
    "            pickle.dump(estimates, f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import savemat\n",
    "\n",
    "working_dir = '/Users/ykhao/Downloads/hour_long_recording/moco/'\n",
    "working_dir = '/Volumes/CLab/hour_long_recording/record3/moco_aff_crop/'\n",
    "save_dir = os.path.join(working_dir, 'volpy_results')\n",
    "\n",
    "pkl_list = glob.glob(os.path.join(save_dir, '*.pkl'))\n",
    "\n",
    "for pkl in pkl_list:\n",
    "    with open(pkl, 'rb') as f:\n",
    "        estimates = pickle.load(f)\n",
    "    img_id = os.path.basename(pkl).replace('_volpy.pkl', '')\n",
    "    #mdic = {'t': estimates['t'][0], 't_rec':estimates['t_rec'][0]}\n",
    "    mdic  = estimates\n",
    "    savemat(os.path.join(save_dir, img_id + '.mat'), mdic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_dir = '/Users/ykhao/Downloads/mouse_2p/test_volpy/'\n",
    "save_dir = os.path.join(working_dir, 'volpy_results')\n",
    "\n",
    "pkl_list = glob.glob(os.path.join(save_dir, '*.pkl'))\n",
    "\n",
    "for pkl in pkl_list:\n",
    "    print(pkl)\n",
    "    with open(pkl, 'rb') as f:\n",
    "        estimates = pickle.load(f)\n",
    "    spikes = estimates['spikes'][0]\n",
    "    t = estimates['t'][0]\n",
    "    t = t - np.median(t)\n",
    "    t_hp = signal_filter(t, 30, 500, order=5)\n",
    "    selectSpikes = np.zeros(t.shape)\n",
    "    selectSpikes[spikes] = 1\n",
    "    sgn = np.mean(t[selectSpikes > 0])\n",
    "    \n",
    "    t_nonspike = np.zeros(t.shape)\n",
    "    t_nonspike[spikes] = 1\n",
    "    t_nonspike = np.convolve(t_nonspike, np.ones(20)/20, 'same') \n",
    "    t_nonspike = t_nonspike == 0 \n",
    "\n",
    "    ff1 = -t_hp * (t_hp < 0) * t_nonspike\n",
    "    Ns = np.sum(ff1 > 0)\n",
    "    noise = np.sqrt(np.divide(np.sum(ff1**2), Ns)) \n",
    "    snr = sgn / noise\n",
    "    print(snr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.path import Path\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "def coords2path(coords):\n",
    "    codes = [Path.MOVETO]\n",
    "    for i, _ in enumerate(coords):\n",
    "        if i > 0:\n",
    "            codes.append(Path.LINETO)\n",
    "    coords = np.append(coords, coords[0][None], axis=0)\n",
    "    codes.append(Path.CLOSEPOLY)\n",
    "\n",
    "    path = Path(coords, codes)\n",
    "    return path\n",
    "\n",
    "def path2mask(path, brain_shape):\n",
    "    pixX = np.arange(brain_shape[1])\n",
    "    pixY = np.arange(brain_shape[0])\n",
    "    xv, yv = np.meshgrid(pixX, pixY)\n",
    "    roi_pix = np.vstack((xv.flatten(), yv.flatten())).T\n",
    "\n",
    "    mask = np.zeros(shape=xv.shape)\n",
    "\n",
    "    xy_indices = np.reshape(path.contains_points(roi_pix, radius=0.5), xv.shape)\n",
    "    mask[xy_indices] = 1\n",
    "\n",
    "    mask = mask == 1\n",
    "    return mask\n",
    "\n",
    "    # ROI_path = img_path.replace('.tif', '_mask.roi')\n",
    "    # img_id = os.path.basename(img_path).replace('.tif', '')\n",
    "    # print(img_id)\n",
    "    # roi = ImagejRoi.fromfile(ROI_path)\n",
    "    # coords = roi.coordinates()\n",
    "    # path = coords2path(coords)\n",
    "    # ROI = path2mask(path, mean_img.shape)\n",
    "    # ROI = ROI.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def remove_moving_frames(img, ROI, threshold=2):\n",
    "#     '''\n",
    "#     Remove frames with large std from the image\n",
    "#     '''\n",
    "#     ROI = ROI.T > 0\n",
    "#     assert img.shape[1:] == ROI.shape\n",
    "#     img_tmp = img.copy()\n",
    "#     img_tmp = img_tmp.reshape(img_tmp.shape[0], -1)\n",
    "#     img_tmp = img_tmp[:, ROI.ravel()]\n",
    "#     t = img_tmp.mean(-1)\n",
    "#     std_t = np.array([t[i:i+200].std() for i in range(0, t.shape[0], 200)])\n",
    "#     # repeat std_t for every 200 frames\n",
    "#     std_t = np.repeat(std_t, 200)\n",
    "#     # high pass filter of std_t\n",
    "#     # std_t = signal_filter(std_t, freq=0.1, fr=5) # detrend\n",
    "#     return img[std_t < std_t.mean() + threshold*std_t.std()]\n",
    "\n",
    "# def remove_moving_frames(img, ROI, threshold=12):\n",
    "#     '''\n",
    "#     Remove frames with large std from the image\n",
    "#     '''\n",
    "#     ROI = ROI.T > 0\n",
    "#     assert img.shape[1:] == ROI.shape\n",
    "#     img_tmp = img.copy()\n",
    "#     img_tmp = img_tmp.reshape(img_tmp.shape[0], -1)\n",
    "#     img_tmp = img_tmp[:, ROI.ravel()]\n",
    "#     t = -img_tmp.mean(-1)\n",
    "#     t = t - np.median(t)\n",
    "#     t = signal_filter(t, freq=1, fr=500) # detrend\n",
    "#     pks = signal.find_peaks(t, height=None)[0]\n",
    "#     pks_snr = t[pks] / t.std()\n",
    "#     clipping_positions = pks[pks_snr > threshold]\n",
    "\n",
    "#     bw = np.zeros_like(t)\n",
    "#     bw[clipping_positions] = 1\n",
    "#     bw = np.convolve(bw, np.ones(100), mode='same')\n",
    "#     bw = bw == 0.0\n",
    "#     return img[bw]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "caiman",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
