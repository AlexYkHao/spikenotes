{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "import h5py\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "import skimage.io as io\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.patches as patches\n",
    "from mpl_toolkits.axes_grid1.anchored_artists import AnchoredSizeBar\n",
    "\n",
    "from caiman.source_extraction.volpy.spikepursuit import signal_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth(x, axis=0, wid=5):\n",
    "    # this is way faster than convolve\n",
    "    if wid < 2:\n",
    "        return x\n",
    "    cumsum_vec = np.cumsum(np.insert(x, 0, 0, axis=axis), axis=axis)\n",
    "    ma_vec = (cumsum_vec[wid:] - cumsum_vec[:-wid]) / wid\n",
    "    y = x.copy()\n",
    "    start_ind = int(np.floor((wid-1)/2))\n",
    "    end_ind = wid-1-start_ind\n",
    "    y[start_ind:-end_ind] = ma_vec\n",
    "    return y\n",
    "\n",
    "def flatten(x, wid):\n",
    "    t = np.arange(x.shape[0])\n",
    "    n_wid = np.ceil(x.shape[0]/wid).astype('int')\n",
    "    xq = np.zeros(n_wid)\n",
    "    tq = np.zeros(n_wid)\n",
    "    for i in range(n_wid):\n",
    "        tmp = x[(i*wid):((i+1)*wid-1)]\n",
    "        lo = np.quantile(tmp, 0.3)\n",
    "        hi = np.quantile(tmp, 0.8)\n",
    "        tmp = tmp[tmp>lo]\n",
    "        tmp = tmp[tmp<hi]\n",
    "        xq[i] = tmp.mean()\n",
    "        tq[i] = t[(i*wid):((i+1)*wid-1)].mean()\n",
    "    y = np.interp(t, tq, xq)\n",
    "    return y\n",
    "\n",
    "def spike_SNR(t, spikes, fr=500):\n",
    "    t = t - np.median(t)\n",
    "    t_hp = signal_filter(t, 30, fr)\n",
    "    selectSpikes = np.zeros(t.shape)\n",
    "    selectSpikes[spikes] = 1\n",
    "    sgn = np.mean(t[selectSpikes > 0])\n",
    "    \n",
    "    t_nonspike = np.zeros(t.shape)\n",
    "    t_nonspike[spikes] = 1\n",
    "    t_nonspike = np.convolve(t_nonspike, np.ones(20)/20, 'same') \n",
    "    t_nonspike = t_nonspike == 0 \n",
    "\n",
    "    ff1 = -t_hp * (t_hp < 0) * t_nonspike\n",
    "    ff1 = ff1[ff1 < np.quantile(ff1, 0.995)]\n",
    "    Ns = np.sum(ff1 > 0)\n",
    "    noise = np.sqrt(np.divide(np.sum(ff1**2), Ns)) \n",
    "    return sgn / noise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AP_ticks(ax, ap_loc, tick_level=1.0, tick_height=0.1, linewidth=0.5, color='r'):\n",
    "    # ref: https://stackoverflow.com/questions/36470343/how-to-draw-a-line-with-matplotlib\n",
    "    n = len(ap_loc)\n",
    "    a = np.c_[ap_loc, -0.5*tick_height + tick_level * np.ones((n,1))]\n",
    "    b = np.c_[ap_loc, 0.5*tick_height + tick_level * np.ones((n,1))]\n",
    "    ax.plot(*np.c_[a, b, a*np.nan].reshape(-1, 2).T, color, linewidth=linewidth)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# extract traces from truncated movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#working_dir = '/Volumes/CLab/hour_long_recording/moco/'\n",
    "working_dir = '/Volumes/CLab/hour_long_recording/record3/moco_aff_crop/'\n",
    "save_dir = os.path.join(working_dir, 'volpy_results')\n",
    "\n",
    "tiff_list = glob.glob(os.path.join(working_dir, '*.tif'))\n",
    "tiff_list.sort()\n",
    "tiff_list"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## non weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten_wid = 250 # frames\n",
    "\n",
    "for img_path in tiff_list:\n",
    "    ## read image and ROI\n",
    "    img = io.imread(img_path)\n",
    "    mean_img = img.mean(axis=0)\n",
    "    ROI_path = img_path[:-10] + 'moco_mask.h5' \n",
    "    img_id = os.path.basename(img_path).replace('.tif', '')\n",
    "    print(img_id)\n",
    "    pkl = os.path.join(save_dir, img_id+'_volpy.pkl') \n",
    "    if not os.path.exists(pkl):\n",
    "        continue\n",
    "    with open(pkl, 'rb') as f:\n",
    "        estimates = pickle.load(f)\n",
    "    with h5py.File(ROI_path, 'r') as fl:\n",
    "        ROI = fl['cell_mask'][()]\n",
    "        BG = fl['bg_mask'][()]\n",
    "    ROI = ROI > 0\n",
    "    BG = BG > 0\n",
    "    raw_trace = img[:, ROI.T].mean(-1)\n",
    "    bg = img[:, BG.T].mean(-1)\n",
    "    f_trace = raw_trace - bg.mean()\n",
    "    baseline = flatten(f_trace, 150)\n",
    "    dff = (f_trace - baseline) / baseline\n",
    "\n",
    "    extracted_mat_file = img_id+'_dff.mat'\n",
    "    mdic = {'raw_trace': raw_trace, 'bg':bg, 'f_trace':f_trace, 'dff':dff, 'baseline':baseline, 'spike_locs':estimates['spikes']}\n",
    "    sio.savemat(os.path.join(working_dir, extracted_mat_file), mdic)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# using SNR and dff value from flattened traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_dir = working_dir = '/Volumes/CLab/hour_long_recording/record3/moco_aff_crop/'\n",
    "mat_list = glob.glob(os.path.join(working_dir, '*dff.mat'))\n",
    "mat_list.sort()\n",
    "traces = []\n",
    "baselines = []\n",
    "SNR = []\n",
    "APs = []\n",
    "for idx, mf in enumerate(mat_list):\n",
    "    # load mat file\n",
    "    mdic = sio.loadmat(mf)\n",
    "    dff = mdic['dff'].squeeze()\n",
    "    spike_locs = mdic['spike_locs'].squeeze()\n",
    "    f_trace = mdic['raw_trace'].squeeze() - mdic['bg'].squeeze()\n",
    "    baseline = flatten(f_trace, 200)\n",
    "    f_trace_flat = f_trace - baseline\n",
    "    traces.append(f_trace)\n",
    "    baselines.append(baseline)\n",
    "    SNR.append(spike_SNR(-f_trace_flat, spike_locs))\n",
    "    APs.append(spike_locs + idx * len(dff))\n",
    "\n",
    "baselines = np.hstack(baselines)\n",
    "traces = np.hstack(traces)\n",
    "APs = np.hstack(APs)\n",
    "\n",
    "baseline_filtered = signal_filter(baselines, 0.01, 500, order=1, mode='low')\n",
    "dff = (traces - baselines) / baseline_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_dir = working_dir = '/Volumes/CLab/hour_long_recording/record3/moco_aff_crop/'\n",
    "\n",
    "mat = sio.loadmat(os.path.join(working_dir, 'AP_summary.mat'))\n",
    "traces = mat['bg_removed_trace'].T\n",
    "dff = mat['dff'].T\n",
    "APs = mat['spikes'].T-1  # -1 is for python index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = smooth(dff, wid=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHUNK = np.round(len(dff)/2).astype('int')\n",
    "zoom_in_region = [\n",
    "    (40500, 43000),\n",
    "    (1609500, 1612000),\n",
    "]  # for mouse M984L FOVXa 20230717\n",
    "zoom_in_region = [(zr[0]-CHUNK*i, zr[1]-CHUNK*i) for i, zr in enumerate(zoom_in_region)]\n",
    "\n",
    "rect = [patches.Rectangle((zr[0], -0.35), zr[1]-zr[0]+500,  1.0, linewidth=0.5, edgecolor='red', fill=False, zorder=2) for zr in zoom_in_region]\n",
    "fig = plt.figure(figsize=(6, 1.6))\n",
    "plt.rcParams['font.size'] = '7'\n",
    "plt.rcParams['font.sans-serif'] = \"Arial\"\n",
    "plt.rcParams['font.family'] = \"sans-serif\"\n",
    "gs1 = gridspec.GridSpec(2, 1)\n",
    "gs1.update(wspace=0., hspace=0.1)\n",
    "axes = [plt.subplot(gs1[i, 0]) for i in range(2)]\n",
    "for i, ax in enumerate(axes):\n",
    "    #ax.axis('off')  \n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.tick_params(axis='y', which='major', direction='out',length=2, width=0.5)\n",
    "    ax.set_yticks(np.linspace(-0.3, 0.6, 4), (np.linspace(-0.3, 0.6, 4)*100).astype('int'))\n",
    "for i in range(2):\n",
    "    spt = np.where(np.logical_and(APs>i*CHUNK, APs<(i+1)*CHUNK))[0]\n",
    "    axes[i].plot(-dff[i*CHUNK:(i+1)*CHUNK], linewidth=0.3)\n",
    "    #axes[i].plot(APs[spt]-i*CHUNK, 0.7 * np.ones(spt.shape), color='red', marker='|', fillstyle='none', linestyle='none', markersize=10)\n",
    "    AP_ticks(axes[i], APs[spt]-i*CHUNK, tick_level=0.7, tick_height=0.12, linewidth=0.4)\n",
    "    axes[i].set_ylim([-0.4, 0.8])\n",
    "    axes[i].set_xlim([0, CHUNK])\n",
    "    roi_box = rect[i]\n",
    "    axes[i].add_patch(rect[i])\n",
    "plt.tight_layout(pad=0, h_pad=None, w_pad=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "caiman",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
