{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-12 23:47:00.345633: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import h5py\n",
    "import pickle\n",
    "import shutil\n",
    "from itertools import chain\n",
    "\n",
    "import numpy as np\n",
    "from skimage import io\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal, ndimage\n",
    "\n",
    "import caiman as cm\n",
    "import caiman.paths\n",
    "from caiman.source_extraction.volpy import utils\n",
    "from caiman.source_extraction.volpy.volparams import volparams\n",
    "from caiman.source_extraction.volpy.volpy import VOLPY\n",
    "from caiman.source_extraction.volpy.spikepursuit import signal_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = None                                # if None, use ROIs for initialization; to reuse weights check reuse weights block \n",
    "\n",
    "fr = 500 \n",
    "template_size = 0.01                          # half size of the window length for spike templates, default is 20 ms \n",
    "context_size = 2                          # number of pixels surrounding the ROI to censor from the background PCA\n",
    "visualize_ROI = False                         # whether to visualize the region of interest inside the context region\n",
    "flip_signal = True                            # Important!! Flip signal or not, True for Voltron indicator, False for others\n",
    "hp_freq_pb = 1 / 3                            # parameter for high-pass filter to remove photobleaching\n",
    "hp_freq = 5\n",
    "clip = 100                                    # maximum number of spikes to form spike template\n",
    "threshold_method = 'adaptive_threshold'       # adaptive_threshold or simple \n",
    "min_spikes= 5                                # minimal spikes to be found  # was 50 for Jiannis' data\n",
    "pnorm = 0.5                                   # a variable deciding the amount of spikes chosen for adaptive threshold method\n",
    "desired_fp = 10**(-4)  # note: was hard-coded for current use case\n",
    "threshold = 3                                 # threshold for finding spikes only used in simple threshold method, Increase the threshold to find less spikes\n",
    "do_plot = False                               # plot detail of spikes, template for the last iteration\n",
    "ridge_bg= 0.01                                # ridge regression regularizer strength for background removement, larger value specifies stronger regularization \n",
    "sub_freq = 20                                 # frequency for subthreshold extraction\n",
    "weight_update = 'ridge'                       # ridge or NMF for weight update\n",
    "n_iter = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_img(img):\n",
    "    '''\n",
    "    Cut initial 600 frames\n",
    "    '''\n",
    "    return img[600:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mouse_dir = '/Volumes/CLab/sungmoo/Real analysis_traces flattened'\n",
    "\n",
    "pre_process = True\n",
    "remove_moving_part = True  # True for Jiannis data, False for Bruker data\n",
    "mouse_list = [glob.glob(os.path.join(mouse_dir, starter+'*')) for starter in['F9', 'M9']]\n",
    "mouse_list = list(chain(*mouse_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Volumes/CLab/sungmoo/Real analysis_traces flattened/F957L',\n",
       " '/Volumes/CLab/sungmoo/Real analysis_traces flattened/F99xR',\n",
       " '/Volumes/CLab/sungmoo/Real analysis_traces flattened/F986L',\n",
       " '/Volumes/CLab/sungmoo/Real analysis_traces flattened/F960R',\n",
       " '/Volumes/CLab/sungmoo/Real analysis_traces flattened/F975R',\n",
       " '/Volumes/CLab/sungmoo/Real analysis_traces flattened/F991R',\n",
       " '/Volumes/CLab/sungmoo/Real analysis_traces flattened/F954R',\n",
       " '/Volumes/CLab/sungmoo/Real analysis_traces flattened/F981R',\n",
       " '/Volumes/CLab/sungmoo/Real analysis_traces flattened/F993L',\n",
       " '/Volumes/CLab/sungmoo/Real analysis_traces flattened/F976L',\n",
       " '/Volumes/CLab/sungmoo/Real analysis_traces flattened/M956R',\n",
       " '/Volumes/CLab/sungmoo/Real analysis_traces flattened/M955L',\n",
       " '/Volumes/CLab/sungmoo/Real analysis_traces flattened/M958R',\n",
       " '/Volumes/CLab/sungmoo/Real analysis_traces flattened/M982L',\n",
       " '/Volumes/CLab/sungmoo/Real analysis_traces flattened/M984L',\n",
       " '/Volumes/CLab/sungmoo/Real analysis_traces flattened/M978R',\n",
       " '/Volumes/CLab/sungmoo/Real analysis_traces flattened/M980R',\n",
       " '/Volumes/CLab/sungmoo/Real analysis_traces flattened/M983R',\n",
       " '/Volumes/CLab/sungmoo/Real analysis_traces flattened/M990L',\n",
       " '/Volumes/CLab/sungmoo/Real analysis_traces flattened/M953L',\n",
       " '/Volumes/CLab/sungmoo/Real analysis_traces flattened/M985L',\n",
       " '/Volumes/CLab/sungmoo/Real analysis_traces flattened/M989R']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mouse_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for mouse in mouse_list:\n",
    "    print(mouse)\n",
    "    working_dir = mouse\n",
    "    img_list = glob.glob(os.path.join(working_dir, '*.tif'))\n",
    "\n",
    "    save_dir = os.path.join(working_dir, 'volpy_results')\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    fail_dir = os.path.join(working_dir, 'failed')\n",
    "    if not os.path.exists(fail_dir):\n",
    "        os.makedirs(fail_dir)\n",
    "\n",
    "    for img_path in img_list:\n",
    "        ## read image and ROI\n",
    "        img = io.imread(img_path)\n",
    "        if pre_process:\n",
    "            img = cut_img(img)\n",
    "        mean_img = img.mean(axis=0)\n",
    "        ROI_path = img_path[:-4] + '_mask.h5'  # only for jiannis data\n",
    "        img_id = os.path.basename(img_path).replace('.tif', '')\n",
    "        print(img_id)\n",
    "        with h5py.File(ROI_path, 'r') as fl:\n",
    "            ROI = fl['cell_mask'][()]\n",
    "        if remove_moving_part:\n",
    "            solid = img.min(axis=0)\n",
    "            solid = solid > 1.0\n",
    "            # erode solid mask\n",
    "            #solid = ndimage.binary_erosion(solid, iterations=1)\n",
    "            ROI = ROI * solid.T\n",
    "        #img = remove_moving_frames(img, ROI)\n",
    "        T, d1, d2 = img.shape\n",
    "        img_reshape = img.reshape(T, d1*d2, order='F')\n",
    "        ## generating memory mapping\n",
    "        mmap_path = caiman.paths.memmap_frames_filename(img_id[:15], [d1, d2], T, 'C')\n",
    "        mmap_path = os.path.join(working_dir, mmap_path)\n",
    "        fp = np.memmap(mmap_path, dtype='float32', mode='w+', shape=(d1*d2, T), order='C')\n",
    "        fp[:] = img_reshape[:].T\n",
    "        fp.flush()\n",
    "        del fp\n",
    "        ## assembly parameters for volpy\n",
    "        ROIs = np.expand_dims(ROI.T, axis=0)\n",
    "        index = list(range(len(ROIs)))     # index of ROIs to be used for spike extraction\n",
    "        opts_dict={'fnames': mmap_path,\n",
    "                'ROIs': ROIs,\n",
    "                'fr': fr,\n",
    "                'index': index,\n",
    "                'weights': weights,\n",
    "                'template_size': template_size, \n",
    "                'context_size': context_size,\n",
    "                'visualize_ROI': visualize_ROI, \n",
    "                'flip_signal': flip_signal,\n",
    "                'hp_freq': hp_freq,\n",
    "                'hp_freq_pb': hp_freq_pb,\n",
    "                'clip': clip,\n",
    "                'threshold_method': threshold_method,\n",
    "                'min_spikes':min_spikes,\n",
    "                'pnorm': pnorm,\n",
    "                #'desired_fp': desired_fp, \n",
    "                'threshold': threshold,\n",
    "                'do_plot':do_plot,\n",
    "                'ridge_bg':ridge_bg,\n",
    "                'sub_freq': sub_freq,\n",
    "                'weight_update': weight_update,\n",
    "                'n_iter': n_iter}\n",
    "\n",
    "        opts = volparams(params_dict=opts_dict)\n",
    "        ## run volpy\n",
    "        if 'dview' in locals():\n",
    "            cm.stop_server(dview=dview)\n",
    "        c, dview, n_processes = cm.cluster.setup_cluster(\n",
    "            backend='local', n_processes=None, single_thread=False)\n",
    "        try:\n",
    "            vpy = VOLPY(n_processes=n_processes, dview=dview, params=opts)\n",
    "            vpy.fit(n_processes=n_processes, dview=dview)\n",
    "            ## visualize and save results\n",
    "            print(np.where(vpy.estimates['locality'])[0])    # neurons that pass locality test\n",
    "            idx = np.where(vpy.estimates['locality'] > 0)[0]\n",
    "            utils.view_components(vpy.estimates, mean_img, [0], save_path=os.path.join(save_dir, img_id + '_summary.png'))\n",
    "            with open(os.path.join(save_dir, img_id + '_volpy.pkl'), 'wb') as f:\n",
    "                pickle.dump(vpy.estimates, f)\n",
    "        except:\n",
    "            shutil.move(src=img_path, dst=os.path.join(working_dir, 'failed'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "caiman",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
